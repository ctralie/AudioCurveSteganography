{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import signal\n",
    "import glob\n",
    "import librosa\n",
    "import time\n",
    "import pickle\n",
    "import subprocess\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import skimage.io\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from imtools import get_voronoi_image, splat_voronoi_image_1nn\n",
    "from audioutils import extract_loudness\n",
    "from tsp import get_tsp_tour\n",
    "sys.path.append(\"../models\")\n",
    "from networks import CurveEncoder, CurveDecoder\n",
    "from losses import mss_loss\n",
    "sys.path.append(\"../data\")\n",
    "from datasets import CurveData, AudioData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d73838",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb47884",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "T = 300\n",
    "samples_per_batch = 10000\n",
    "win_length = 1024\n",
    "sr = 44100\n",
    "\n",
    "curve_train = CurveData(np.arange(10), n_samples, T, samples_per_batch)\n",
    "curve_test  = CurveData(np.arange(10, 15), n_samples, T, samples_per_batch)\n",
    "\n",
    "audio_train = AudioData(\"../data/musdb18hq/train/*/mixture.wav\", T, samples_per_batch, win_length, sr)\n",
    "audio_test  = AudioData(\"../data/musdb18hq/test/*/mixture.wav\",  T, samples_per_batch, win_length, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(curve_train, batch_size=16, shuffle=True)\n",
    "Y = next(iter(loader)).numpy()\n",
    "print(Y.shape)\n",
    "plt.scatter(Y[0, :, 0], Y[0, :, 1], c=Y[0, :, 2::])\n",
    "plt.plot(Y[0, :, 0], Y[0, :, 1], c='k', linewidth=1)\n",
    "\n",
    "loader = DataLoader(audio_train, batch_size=16, shuffle=True)\n",
    "X, L = next(iter(loader))\n",
    "ipd.Audio(X[0, :], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b5830",
   "metadata": {},
   "source": [
    "# Encoder / Decoder Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed214aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_loader = DataLoader(curve_train, batch_size=16, shuffle=True)\n",
    "audio_loader = DataLoader(audio_train, batch_size=16, shuffle=True)\n",
    "Y = next(iter(curve_loader))\n",
    "X, L = next(iter(audio_loader))\n",
    "\n",
    "mlp_depth = 3\n",
    "n_units = 256\n",
    "n_taps = 50\n",
    "encoder = CurveEncoder(mlp_depth, n_units, n_taps, win_length)\n",
    "decoder = CurveDecoder(mlp_depth, n_units, win_length)\n",
    "print(\"Encoder params\", encoder.get_num_parameters())\n",
    "print(\"Decoder params\", decoder.get_num_parameters())\n",
    "N = encoder(Y, L)\n",
    "ipd.Audio(N.detach().numpy()[1, :], rate=sr)\n",
    "XN = X + N\n",
    "YOut = decoder(XN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5adf2b",
   "metadata": {},
   "source": [
    "# Test Example - Layla And Smooth Criminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48484c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "n_points = 3000\n",
    "n_iters = 100\n",
    "I = skimage.io.imread(\"../data/images/layla.png\")\n",
    "N = min(I.shape[0], I.shape[1])\n",
    "J, YLayla, final_cost = get_voronoi_image(I, device, n_points, n_neighbs=2, n_iters=n_iters, verbose=False, plot_iter_interval=0, use_lsqr=False)\n",
    "YLayla = get_tsp_tour(YLayla)\n",
    "#YLayla = curve_train.Ys[100]\n",
    "plt.imshow(splat_voronoi_image_1nn(YLayla, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9750be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "YLayla = np.array(YLayla, dtype=np.float32)\n",
    "hop_length = win_length//2\n",
    "TLayla = YLayla.shape[0]\n",
    "YLayla = torch.from_numpy(YLayla).to(device)\n",
    "YLayla = YLayla.view(1, TLayla, 5)\n",
    "xsmooth, _ = librosa.load(\"../data/tunes/smoothcriminal.mp3\", sr=sr)\n",
    "#xsmooth, _ = librosa.load(\"../data/musdb18hq/test/Arise - Run Run Run/mixture.wav\", sr=sr)\n",
    "xsmooth = xsmooth[sr*15::] # Cut off quieter beginning\n",
    "lsmooth = extract_loudness(xsmooth, sr, hop_length, win_length)\n",
    "lsmooth = np.array(lsmooth[0:TLayla], dtype=np.float32)\n",
    "xsmooth = np.array(xsmooth[0:hop_length*(TLayla-1)+win_length], dtype=np.float32)\n",
    "xsmooth = torch.from_numpy(xsmooth[None, :]).to(device)\n",
    "lsmooth = torch.from_numpy(lsmooth[None, :, None]).to(device)\n",
    "print(xsmooth.shape, lsmooth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7deb662",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device: \", device)\n",
    "\n",
    "## Step 2: Create model with a test batch\n",
    "noise_only = False\n",
    "mlp_depth = 3\n",
    "n_units = 512\n",
    "n_taps = 200\n",
    "pre_scale = 1\n",
    "lam_xy = 1000 # Weight for geometry curve fit\n",
    "lam_rgb = 200 # Weight for rgb curve fit\n",
    "encoder = CurveEncoder(mlp_depth, n_units, n_taps, win_length, pre_scale)\n",
    "encoder = encoder.to(device)\n",
    "decoder = CurveDecoder(mlp_depth, n_units, win_length)\n",
    "decoder = decoder.to(device)\n",
    "print(\"Encoder params\", encoder.get_num_parameters())\n",
    "print(\"Decoder params\", decoder.get_num_parameters())\n",
    "\n",
    "## Step 3: Setup the loss function\n",
    "batch_size=16\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "# Start at learning rate of 0.001, rate decay of 0.98 factor every 10,000 steps\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10000/len(curve_train), gamma=0.98)\n",
    "\n",
    "n_epochs = 10000\n",
    "xy_losses = []\n",
    "rgb_losses = []\n",
    "audio_losses = []\n",
    "\n",
    "test_xy_losses = []\n",
    "test_rgb_losses = []\n",
    "test_audio_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbcf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fac = 0.7\n",
    "plt.figure(figsize=(fac*18, fac*18))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #####################    STEP 1:  TRAIN     ##################### \n",
    "    curve_loader = DataLoader(curve_train, batch_size=16, shuffle=True)\n",
    "    audio_loader = DataLoader(audio_train, batch_size=16, shuffle=True)\n",
    "    \n",
    "    train_xy_loss = 0\n",
    "    train_rgb_loss = 0\n",
    "    train_audio_loss = 0\n",
    "    for batch_num, (Y, (X, L)) in enumerate(zip(curve_loader, audio_loader)): # Go through each mini batch\n",
    "        # Move inputs/outputs to GPU\n",
    "        Y = Y.to(device)\n",
    "        X = X.to(device)\n",
    "        L = L.to(device)\n",
    "        # Reset the optimizer's gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Encode the curve\n",
    "        N = encoder(Y, L)\n",
    "        # Add filtered noise to audio and decode\n",
    "        if noise_only:\n",
    "            XN = N\n",
    "        else:\n",
    "            XN = X + N\n",
    "        mp3noise = get_mp3_noise(XN, sr) # Add on mp3 noise as a constant\n",
    "        YOut = decoder(XN + mp3noise)\n",
    "        \n",
    "        # Add a loss term for the MSS fit of XN to X, as well as the L1 fit of Y to YOut\n",
    "        loss_audio = mss_loss(X, XN)\n",
    "        loss_xy = torch.mean(torch.abs(Y[:, :, 0:2]-YOut[:, :, 0:2]))\n",
    "        loss_rgb = torch.mean(torch.abs(Y[:, :, 2::]-YOut[:, :, 2::]))\n",
    "        \n",
    "        loss = lam_xy*loss_xy + lam_rgb*loss_rgb + loss_audio\n",
    "        \n",
    "        train_xy_loss += loss_xy.item()\n",
    "        train_rgb_loss += loss_rgb.item()\n",
    "        train_audio_loss += loss_audio.item()\n",
    "        \n",
    "        # Compute the gradients of the loss function with respect\n",
    "        # to all of the parameters of the model\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    last_Y = Y\n",
    "    last_YOut = YOut\n",
    "        \n",
    "    audio_losses.append(train_audio_loss/len(audio_loader))\n",
    "    xy_losses.append(train_xy_loss/len(audio_loader))\n",
    "    rgb_losses.append(train_rgb_loss/len(audio_loader))\n",
    "    \n",
    "    print(\"Epoch {}, audio loss {:.3f}, xy loss {:.3f}, rgb loss {:.3f}\".format(epoch, audio_losses[-1], xy_losses[-1], rgb_losses[-1]))\n",
    "    scheduler.step()\n",
    "    \n",
    "    #####################    STEP 2:  TEST     ##################### \n",
    "    curve_loader = DataLoader(curve_test, batch_size=16)\n",
    "    audio_loader = DataLoader(audio_test, batch_size=16)\n",
    "    test_xy_loss = 0\n",
    "    test_rgb_loss = 0\n",
    "    test_audio_loss = 0\n",
    "    for batch_num, (Y, (X, L)) in enumerate(zip(curve_loader, audio_loader)): # Go through each mini batch\n",
    "        # Move inputs/outputs to GPU\n",
    "        Y = Y.to(device)\n",
    "        X = X.to(device)\n",
    "        L = L.to(device)\n",
    "        # Encode the curve\n",
    "        N = encoder(Y, L)\n",
    "        # Add filtered noise to audio and decode\n",
    "        if noise_only:\n",
    "            XN = N\n",
    "        else:\n",
    "            XN = X + N\n",
    "        YOut = decoder(XN)\n",
    "        # Add a loss term for the MSS fit of XN to X, as well as the L1 fit of Y to YOut\n",
    "        loss_audio = mss_loss(X, XN)\n",
    "        loss_xy = torch.mean(torch.abs(Y[:, :, 0:2]-YOut[:, :, 0:2]))\n",
    "        loss_rgb = torch.mean(torch.abs(Y[:, :, 2::]-YOut[:, :, 2::]))\n",
    "        test_xy_loss += loss_xy.item()\n",
    "        test_rgb_loss += loss_rgb.item()\n",
    "        test_audio_loss += loss_audio.item()\n",
    "        \n",
    "    last_Y_test = Y\n",
    "    last_YOut_test = YOut\n",
    "        \n",
    "    test_audio_losses.append(test_audio_loss/len(audio_loader))\n",
    "    test_xy_losses.append(test_xy_loss/len(audio_loader))\n",
    "    test_rgb_losses.append(test_rgb_loss/len(audio_loader))\n",
    "    \n",
    "    \n",
    "    #####################    STEP 3:  LAYLA     ##################### \n",
    "    N = encoder(YLayla, lsmooth)\n",
    "    if noise_only:\n",
    "        XN = N\n",
    "    else:\n",
    "        XN = xsmooth + N\n",
    "    YOut = decoder(XN)\n",
    "    loss_xy_layla  = torch.mean(torch.abs(YLayla[:, :, 0:2]-YOut[:, :, 0:2]))\n",
    "    loss_rgb_layla = torch.mean(torch.abs(YLayla[:, :, 2::]-YOut[:, :, 2::]))\n",
    "    YOut = YOut.detach().cpu().numpy()\n",
    "    YOut = YOut[0, :, :]\n",
    "    YOut[:, 2::] = np.maximum(YOut[:, 2::], 0)\n",
    "    YOut[:, 2::] = np.minimum(YOut[:, 2::], 1)\n",
    "    # Save as an mp3 and repeat\n",
    "    x = XN.detach().cpu().numpy()[0, :]\n",
    "    x = x/np.max(x)\n",
    "    x = np.array(x*32768, dtype=np.int16)\n",
    "    wavfile.write(\"Epoch{}.wav\".format(epoch), sr, x)\n",
    "    \n",
    "    x = N.detach().cpu().numpy()[0, :]\n",
    "    x = x/np.max(x)\n",
    "    x = np.array(x*32768, dtype=np.int16)\n",
    "    wavfile.write(\"Epoch{}Noise.wav\".format(epoch), sr, x)\n",
    "    \n",
    "    subprocess.call(\"ffmpeg -i Epoch{}.wav Epoch{}.mp3\".format(epoch, epoch).split(), stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    z, sr = librosa.load(\"Epoch{}.mp3\".format(epoch), sr=sr)\n",
    "    z = torch.from_numpy(z[None, :]).to(XN)\n",
    "    YOut_mp3 = decoder(z)\n",
    "    loss_xy_layla_mp3  = torch.mean(torch.abs(YLayla[:, :, 0:2]-YOut_mp3[:, :, 0:2]))\n",
    "    loss_rgb_layla_mp3 = torch.mean(torch.abs(YLayla[:, :, 2::]-YOut_mp3[:, :, 2::]))\n",
    "    YOut_mp3 = YOut_mp3.detach().cpu().numpy()\n",
    "    YOut_mp3 = YOut_mp3[0, :, :]\n",
    "    YOut_mp3[:, 2::] = np.maximum(YOut_mp3[:, 2::], 0)\n",
    "    YOut_mp3[:, 2::] = np.minimum(YOut_mp3[:, 2::], 1)\n",
    "    \n",
    "\n",
    "    \n",
    "    #####################    STEP 4: PLOT    ##################### \n",
    "    plt.clf()\n",
    "    plt.subplot(331)\n",
    "    plt.imshow(splat_voronoi_image_1nn(YOut, 200, 200))\n",
    "    plt.title(\"Layla Wav Reconstruction\")\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(splat_voronoi_image_1nn(YOut_mp3, 200, 200))\n",
    "    plt.title(\"Layla Mp3 Reconstruction\")\n",
    "    \n",
    "    plt.subplot(333)\n",
    "    plt.plot(audio_losses)\n",
    "    plt.plot(lam_xy*np.array(xy_losses))\n",
    "    plt.plot(lam_rgb*np.array(rgb_losses))\n",
    "    plt.legend([\"Audio ({:.3f})\".format(audio_losses[-1]), \n",
    "                \"xy ({:.3f})\".format(xy_losses[-1]),\n",
    "                \"rgb ({:.3f})\".format(rgb_losses[-1])])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Scaled Loss\")\n",
    "    plt.title(\"Epoch {}, Train Losses\".format(epoch)) \n",
    "    \n",
    "    \n",
    "    plt.subplot(334)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 0], YOut[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"X Coord Layla (Loss {:.3f})\".format(loss_xy_layla))\n",
    "    plt.subplot(335)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 2], YOut[:, 2])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"R Coord Layla (Loss {:.3f})\".format(loss_rgb_layla))\n",
    "    \n",
    "    plt.subplot(336)\n",
    "    plt.plot(test_audio_losses)\n",
    "    plt.plot(lam_xy*np.array(test_xy_losses))\n",
    "    plt.plot(lam_rgb*np.array(test_rgb_losses))\n",
    "    plt.legend([\"Audio ({:.3f})\".format(test_audio_losses[-1]), \n",
    "                \"xy ({:.3f})\".format(test_xy_losses[-1]),\n",
    "                \"rgb ({:.3f})\".format(test_rgb_losses[-1])])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Scaled Loss\")\n",
    "    plt.title(\"Test Losses\")\n",
    "    \n",
    "    plt.subplot(337)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 0], YOut_mp3[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Mp3 X Coord Layla (Loss {:.3f})\".format(loss_xy_layla_mp3))\n",
    "    plt.subplot(338)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 2], YOut_mp3[:, 2])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Mp3 R Coord Layla (Loss {:.3f})\".format(loss_rgb_layla_mp3))\n",
    "    \n",
    "    plt.subplot(339)\n",
    "    textstr = \"Epoch {}\\n\\nlam_xy = {}\\nlam_rgb = {}\\npre_scale={}\\nn_units={}\\nn_taps={}\\npre_scale={}\".format(epoch, lam_xy, lam_rgb, pre_scale, n_units, n_taps, pre_scale)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.savefig(\"Epoch{}.png\".format(epoch), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419179b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
