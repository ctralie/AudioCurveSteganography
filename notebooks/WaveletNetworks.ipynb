{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_audiomentations import Compose, PitchShift\n",
    "from scipy import signal\n",
    "import glob\n",
    "import librosa\n",
    "import time\n",
    "import pickle\n",
    "import subprocess\n",
    "from skimage.transform import resize\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import skimage.io\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from imtools import get_voronoi_image, splat_voronoi_image_1nn\n",
    "from audioutils import extract_loudness, get_mp3_noise, get_chroma_filterbank, get_batch_chroma\n",
    "from tsp import get_tsp_tour\n",
    "from wavelets2d import get_color_wavelet_tsp, invert_sparse_coefficients\n",
    "sys.path.append(\"../models\")\n",
    "from networks import CurveEncoder, CurveDecoder\n",
    "from losses import mss_loss\n",
    "sys.path.append(\"../data\")\n",
    "from dataset import CurveData, AudioData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d73838",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb47884",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "T = 300\n",
    "samples_per_batch = 10000\n",
    "win_length = 1024\n",
    "hop_length = win_length//2\n",
    "sr = 44100\n",
    "\n",
    "curve_train = CurveData(np.arange(10), n_samples, T, samples_per_batch, voronoi=False)\n",
    "curve_test  = CurveData(np.arange(10, 15), n_samples, T, samples_per_batch, voronoi=False)\n",
    "\n",
    "audio_train = AudioData(\"../data/musdb18hq/train/*/mixture.wav\", T, samples_per_batch, win_length, sr)\n",
    "audio_test  = AudioData(\"../data/musdb18hq/test/*/mixture.wav\",  T, samples_per_batch, win_length, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5adf2b",
   "metadata": {},
   "source": [
    "# Test Example - Layla And Smooth Criminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48484c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_levels = 5\n",
    "n_points = 3000\n",
    "box_scale = 50\n",
    "I = skimage.io.imread(\"../data/images/layla.png\")\n",
    "I = resize(I, (256, 256), anti_aliasing=True)\n",
    "YLayla = get_color_wavelet_tsp(I, n_levels, n_points, box_scale)\n",
    "J = invert_sparse_coefficients(YLayla, I.shape[0], n_levels, box_scale)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(J)\n",
    "plt.subplot(122)\n",
    "plt.plot(YLayla[:, 0], YLayla[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9750be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device: \", device)\n",
    "YLayla = np.array(YLayla, dtype=np.float32)\n",
    "TLayla = YLayla.shape[0]\n",
    "YLayla = torch.from_numpy(YLayla).to(device)\n",
    "YLayla = YLayla.view(1, TLayla, 5)\n",
    "xsmooth, _ = librosa.load(\"../data/tunes/smoothcriminal.mp3\", sr=sr)\n",
    "#xsmooth, _ = librosa.load(\"../data/musdb18hq/test/Arise - Run Run Run/mixture.wav\", sr=sr)\n",
    "xsmooth = xsmooth[sr*15::] # Cut off quieter beginning\n",
    "lsmooth = extract_loudness(xsmooth, sr, hop_length, win_length)\n",
    "lsmooth = np.array(lsmooth[0:TLayla], dtype=np.float32)\n",
    "xsmooth = np.array(xsmooth[0:hop_length*(TLayla-1)+win_length], dtype=np.float32)\n",
    "xsmooth = torch.from_numpy(xsmooth[None, :]).to(device)\n",
    "lsmooth = torch.from_numpy(lsmooth[None, :, None]).to(device)\n",
    "print(xsmooth.shape, lsmooth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7deb662",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters for encoder/decoder\n",
    "mlp_depth = 3\n",
    "n_units = 512\n",
    "n_taps = 200\n",
    "noise_eps = 0.2\n",
    "use_mp3_noise = True\n",
    "pre_scale = 1\n",
    "lam_xy = 1000 # Weight for geometry curve fit\n",
    "lam_rgb = 400 # Weight for rgb curve fit\n",
    "encoder = CurveEncoder(mlp_depth, n_units, n_taps, win_length, pre_scale)\n",
    "encoder = encoder.to(device)\n",
    "decoder = CurveDecoder(mlp_depth, n_units, win_length, voronoi=False)\n",
    "decoder = decoder.to(device)\n",
    "print(\"Encoder params\", encoder.get_num_parameters())\n",
    "print(\"Decoder params\", decoder.get_num_parameters())\n",
    "\n",
    "## Setup the loss function\n",
    "batch_size=16\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "# Start at learning rate of 0.001, rate decay of 0.98 factor every 10,000 steps\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10000/len(curve_train), gamma=0.98)\n",
    "\n",
    "n_epochs = 100\n",
    "xy_losses = []\n",
    "rgb_losses = []\n",
    "audio_losses = []\n",
    "\n",
    "test_xy_losses = []\n",
    "test_rgb_losses = []\n",
    "test_audio_losses = []\n",
    "\n",
    "## Setup chroma filterbank and hann window for STFT\n",
    "chroma_filterbank = get_chroma_filterbank(sr, win_length).to(device)\n",
    "hann = torch.hann_window(win_length).to(device)\n",
    "CLayla = get_batch_chroma(xsmooth, win_length, hop_length, hann, chroma_filterbank)\n",
    "\n",
    "## Setup data augmentation\n",
    "pitch_shifter = PitchShift(sample_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e618aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_loader = DataLoader(curve_train, batch_size=16, shuffle=True)\n",
    "audio_loader = DataLoader(audio_train, batch_size=16, shuffle=True)\n",
    "\n",
    "(Y, (X, L)) = next(zip(curve_loader, audio_loader))\n",
    "Y = Y.to(device)\n",
    "X = X.to(device)\n",
    "L = L.to(device)\n",
    "C = get_batch_chroma(X, win_length, hop_length, hann, chroma_filterbank)\n",
    "N = encoder(Y, L, C)\n",
    "XN = X + N\n",
    "XYOut, RGBOut = decoder(XN)\n",
    "print(XYOut.shape, RGBOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbcf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fac = 0.7\n",
    "plt.figure(figsize=(fac*18, fac*18))\n",
    "\n",
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    #####################    STEP 1:  TRAIN     ##################### \n",
    "    curve_loader = DataLoader(curve_train, batch_size=16, shuffle=True)\n",
    "    audio_loader = DataLoader(audio_train, batch_size=16, shuffle=True)\n",
    "    \n",
    "    train_xy_loss = 0\n",
    "    train_rgb_loss = 0\n",
    "    train_audio_loss = 0\n",
    "    tic = time.time()\n",
    "    n_per_batch = len(audio_loader)\n",
    "    for batch_num, (Y, (X, L)) in enumerate(zip(curve_loader, audio_loader)): # Go through each mini batch\n",
    "        # Reset the optimizer's gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move inputs/outputs to GPU\n",
    "        Y = Y.to(device)\n",
    "        X = X.to(device)\n",
    "        L = L.to(device)\n",
    "        \n",
    "        # Do data augmentation on the audio samples X\n",
    "        X = pitch_shifter(X.view(X.shape[0], 1, X.shape[1]))[:, 0, :]\n",
    "        \n",
    "        \n",
    "        # Compute chroma and encode the curve\n",
    "        C = get_batch_chroma(X, win_length, hop_length, hann, chroma_filterbank)\n",
    "        N = encoder(Y, L, C)\n",
    "        \n",
    "        # Add filtered noise to audio and decode\n",
    "        XN = X + N\n",
    "        if noise_eps == 0 or np.random.rand() < 0.5:\n",
    "            XYOut, RGBOut = decoder(XN)\n",
    "        else:\n",
    "            if use_mp3_noise:\n",
    "                added_noise = get_mp3_noise(XN, sr)\n",
    "            else:\n",
    "                added_noise = torch.randn(XN.shape).to(XN)\n",
    "            XYOut, RGBOut = decoder(XN + noise_eps*added_noise)\n",
    "        \n",
    "        # Add a loss term for the MSS fit of XN to X, as well as the L1 fit of Y to YOut\n",
    "        loss_audio = mss_loss(X, XN)\n",
    "        loss_xy = torch.mean(torch.abs(Y[:, :, 0:2]-XYOut)/torch.abs(0.1+Y[:, :, 0:2]))\n",
    "        loss_rgb = torch.mean(torch.abs(Y[:, :, 2::]-RGBOut))\n",
    "        loss = lam_xy*loss_xy + lam_rgb*loss_rgb + loss_audio\n",
    "        train_xy_loss += loss_xy.item()\n",
    "        train_rgb_loss += loss_rgb.item()\n",
    "        train_audio_loss += loss_audio.item()\n",
    "\n",
    "        \n",
    "        # Compute the gradients of the loss function with respect\n",
    "        # to all of the parameters of the model\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        dt = time.time()-tic\n",
    "        rate = dt/(batch_num+1)\n",
    "        time_left = (rate*n_per_batch - dt)\n",
    "        minutes = int(np.floor(time_left/60))\n",
    "        seconds = int(time_left-60*minutes)\n",
    "        ipd.clear_output()\n",
    "        print(\"Epoch {}, batch {} of {}, {}m{}s left\".format(epoch, batch_num+1, n_per_batch, minutes, seconds), flush=True)\n",
    "        \n",
    "    last_Y = Y\n",
    "    last_XYOut = XYOut\n",
    "    last_RGBOut = RGBOut\n",
    "        \n",
    "    audio_losses.append(train_audio_loss/len(audio_loader))\n",
    "    xy_losses.append(train_xy_loss/len(audio_loader))\n",
    "    rgb_losses.append(train_rgb_loss/len(audio_loader))\n",
    "    \n",
    "    print(\"Epoch {}, audio loss {:.3f}, xy loss {:.3f}, rgb loss {:.3f}\".format(epoch, audio_losses[-1], xy_losses[-1], rgb_losses[-1]))\n",
    "    scheduler.step()\n",
    "    \n",
    "    #####################    STEP 2:  TEST     ##################### \n",
    "    curve_loader = DataLoader(curve_test, batch_size=16)\n",
    "    audio_loader = DataLoader(audio_test, batch_size=16)\n",
    "    test_xy_loss = 0\n",
    "    test_rgb_loss = 0\n",
    "    test_audio_loss = 0\n",
    "    for batch_num, (Y, (X, L)) in enumerate(zip(curve_loader, audio_loader)): # Go through each mini batch\n",
    "        # Move inputs/outputs to GPU\n",
    "        Y = Y.to(device)\n",
    "        X = X.to(device)\n",
    "        L = L.to(device)\n",
    "        # Compute chroma and encode the curve\n",
    "        C = get_batch_chroma(X, win_length, hop_length, hann, chroma_filterbank)\n",
    "        N = encoder(Y, L, C)\n",
    "        # Add filtered noise to audio and decode\n",
    "        XN = X + N\n",
    "        if not use_mp3_noise:\n",
    "            added_noise = torch.randn(XN.shape).to(XN)\n",
    "            XYOut, RGBOut = decoder(XN + noise_eps*added_noise)\n",
    "        else:\n",
    "            # Skip adding mp3 noise for speed\n",
    "            XYOut, RGBOut = decoder(XN)\n",
    "        # Add a loss term for the MSS fit of XN to X, as well as the L1 fit of Y to YOut\n",
    "        loss_audio = mss_loss(X, XN)\n",
    "        loss_xy = torch.mean(torch.abs(Y[:, :, 0:2]-XYOut)/torch.abs(0.1+Y[:, :, 0:2]))\n",
    "        loss_rgb = torch.mean(torch.abs(Y[:, :, 2::]-RGBOut))\n",
    "        test_xy_loss += loss_xy.item()\n",
    "        test_rgb_loss += loss_rgb.item()\n",
    "        test_audio_loss += loss_audio.item()\n",
    "        \n",
    "    last_Y_test = Y\n",
    "    last_XYOut_test = XYOut\n",
    "    last_RGBOut_test = RGBOut\n",
    "        \n",
    "    test_audio_losses.append(test_audio_loss/len(audio_loader))\n",
    "    test_xy_losses.append(test_xy_loss/len(audio_loader))\n",
    "    test_rgb_losses.append(test_rgb_loss/len(audio_loader))\n",
    "    \n",
    "    \n",
    "    #####################    STEP 3:  LAYLA     ##################### \n",
    "    N = encoder(YLayla, lsmooth, CLayla)\n",
    "    XN = xsmooth + N\n",
    "    added_noise = torch.randn(XN.shape).to(XN)\n",
    "    XYOut, RGBOut = decoder(XN + noise_eps*added_noise)\n",
    "    loss_xy_layla  = torch.mean(torch.abs(YLayla[:, :, 0:2]-XYOut)/torch.abs(0.1+YLayla[:, :, 0:2]))\n",
    "    loss_rgb_layla = torch.mean(torch.abs(YLayla[:, :, 2::]-RGBOut))\n",
    "    XYOut = XYOut.detach().cpu().numpy()[0, :, :]\n",
    "    RGBOut = RGBOut.detach().cpu().numpy()[0, :, :]\n",
    "    XYRGBOut = np.concatenate((XYOut, RGBOut), axis=1)\n",
    "    LaylaOut = invert_sparse_coefficients(XYRGBOut, I.shape[0], n_levels, box_scale)\n",
    "    LaylaOut[LaylaOut < 0] = 0\n",
    "    LaylaOut[LaylaOut > 1] = 1\n",
    "    \n",
    "    # Save as an mp3 and repeat\n",
    "    x = XN.detach().cpu().numpy()[0, :]\n",
    "    x = x/np.max(x)\n",
    "    x = np.array(x*32768, dtype=np.int16)\n",
    "    wavfile.write(\"Epoch{}.wav\".format(epoch), sr, x)\n",
    "    \n",
    "    x = N.detach().cpu().numpy()[0, :]\n",
    "    x = x/np.max(x)\n",
    "    x = np.array(x*32768, dtype=np.int16)\n",
    "    wavfile.write(\"Epoch{}Noise.wav\".format(epoch), sr, x)\n",
    "    \n",
    "    subprocess.call(\"ffmpeg -i Epoch{}.wav Epoch{}.mp3\".format(epoch, epoch).split(), stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    z, sr = librosa.load(\"Epoch{}.mp3\".format(epoch), sr=sr)\n",
    "    z = torch.from_numpy(z[None, :]).to(XN)\n",
    "    XYOut_mp3, RGBOut_mp3 = decoder(z)\n",
    "    loss_xy_layla_mp3  = torch.mean(torch.abs(YLayla[:, :, 0:2]-XYOut_mp3)/torch.abs(0.1+YLayla[:, :, 0:2]))\n",
    "    loss_rgb_layla_mp3 = torch.mean(torch.abs(YLayla[:, :, 2::]-RGBOut_mp3))\n",
    "    XYOut_mp3 = XYOut_mp3.detach().cpu().numpy()[0, :, :]\n",
    "    RGBOut_mp3 = RGBOut_mp3.detach().cpu().numpy()[0, :, :]\n",
    "    XYRGBOut_mp3 = np.concatenate((XYOut_mp3, RGBOut_mp3), axis=1)\n",
    "    LaylaOut_mp3 = invert_sparse_coefficients(XYRGBOut_mp3, I.shape[0], n_levels, box_scale)\n",
    "    LaylaOut_mp3[LaylaOut_mp3 < 0] = 0\n",
    "    LaylaOut_mp3[LaylaOut_mp3 > 1] = 1\n",
    "\n",
    "    \n",
    "    #####################    STEP 4: PLOT    ##################### \n",
    "    plt.clf()\n",
    "    plt.subplot(331)\n",
    "    plt.imshow(LaylaOut)\n",
    "    plt.title(\"Layla Wav Reconstruction\")\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(LaylaOut_mp3)\n",
    "    plt.title(\"Layla Mp3 Reconstruction\")\n",
    "    \n",
    "    plt.subplot(333)\n",
    "    plt.plot(audio_losses)\n",
    "    plt.plot(lam_xy*np.array(xy_losses))\n",
    "    plt.plot(lam_rgb*np.array(rgb_losses))\n",
    "    plt.legend([\"Audio ({:.3f})\".format(audio_losses[-1]), \n",
    "                \"xy ({:.3f})\".format(xy_losses[-1]),\n",
    "                \"rgb ({:.3f})\".format(rgb_losses[-1])])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Scaled Loss\")\n",
    "    plt.title(\"Epoch {}, Train Losses\".format(epoch)) \n",
    "    \n",
    "    \n",
    "    plt.subplot(334)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 0], XYOut[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Wav X Coord Layla (Loss {:.3f})\".format(loss_xy_layla))\n",
    "    plt.subplot(335)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 2], RGBOut[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Wav R Coord Layla (Loss {:.3f})\".format(loss_rgb_layla))\n",
    "    \n",
    "    plt.subplot(336)\n",
    "    plt.plot(test_audio_losses)\n",
    "    plt.plot(lam_xy*np.array(test_xy_losses))\n",
    "    plt.plot(lam_rgb*np.array(test_rgb_losses))\n",
    "    plt.legend([\"Audio ({:.3f})\".format(test_audio_losses[-1]), \n",
    "                \"xy ({:.3f})\".format(test_xy_losses[-1]),\n",
    "                \"rgb ({:.3f})\".format(test_rgb_losses[-1])])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Scaled Loss\")\n",
    "    plt.title(\"Test Losses\")\n",
    "    \n",
    "    plt.subplot(337)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 0], XYOut_mp3[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Mp3 X Coord Layla (Loss {:.3f})\".format(loss_xy_layla_mp3))\n",
    "    plt.subplot(338)\n",
    "    plt.scatter(YLayla.detach().cpu()[0, :, 2], RGBOut_mp3[:, 0])\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(\"Mp3 R Coord Layla (Loss {:.3f})\".format(loss_rgb_layla_mp3))\n",
    "    \n",
    "    plt.subplot(339)\n",
    "    textstr = \"Epoch {}\\n\\nlam_xy = {}\\nlam_rgb = {}\\npre_scale={}\\nn_units={}\\nn_taps={}\\npre_scale={}\".format(epoch, lam_xy, lam_rgb, pre_scale, n_units, n_taps, pre_scale)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.savefig(\"Epoch{}.png\".format(epoch), bbox_inches='tight')\n",
    "    \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
