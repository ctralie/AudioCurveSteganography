% Example bibtex file for ISMIR Template

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%              TSP Art Papers               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

@inproceedings{secord2002weighted,
  title={Weighted voronoi stippling},
  author={Secord, Adrian},
  booktitle={Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering},
  pages={37--43},
  year={2002}
}

% Cite as another paper that uses edges in stippling
@incollection{li2011structure,
  title={Structure-preserving stippling by priority-based error diffusion},
  author={Li, Hua and Mould, David},
  booktitle={Proceedings of Graphics Interface 2011},
  pages={127--134},
  year={2011}
}

@article{bosch2004continuous,
  title={Continuous line drawings via the traveling salesman problem},
  author={Bosch, Robert and Herman, Adrianne},
  journal={Operations research letters},
  volume={32},
  number={4},
  pages={302--303},
  year={2004},
  publisher={Amsterdam, Netherlands: North-Holland, 1981-}
}

@inproceedings{kaplan2005tsp,
  title={TSP art},
  author={Kaplan, Craig S and Bosch, Robert},
  booktitle={Renaissance Banff: Mathematics, music, art, culture},
  pages={301--308},
  year={2005}
}

@inproceedings{bosch2008connecting,
  title={Connecting the dots: the ins and outs of TSP art},
  author={Bosch, Robert},
  booktitle={Bridges Leeuwarden: Mathematics, Music, Art, Architecture, Culture},
  pages={235--242},
  year={2008}
}

@article{bosch2009jordan,
  title={Jordan as a Jordan curve},
  author={Bosch, Robert},
  journal={Mathematical Wizardry for a Gardner},
  pages={175},
  year={2009},
  publisher={AK Peters, Wellesley, MA}
}

@article{johnson1997traveling,
  title={The traveling salesman problem: A case study in local optimization},
  author={Johnson, David S and McGeoch, Lyle A},
  journal={Local search in combinatorial optimization},
  volume={1},
  number={1},
  pages={215--310},
  year={1997},
  publisher={Citeseer}
}

@article{applegate2001concorde,
  title={Concorde-a code for solving traveling salesman problems},
  author={Applegate, David},
  journal={http://www. math. princeton. edu/tsp/concorde. html},
  year={2001}
}

@article{canny1986computational,
  title={A computational approach to edge detection},
  author={Canny, John},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  number={6},
  pages={679--698},
  year={1986},
  publisher={Ieee}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%      Steganography/Sonification           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

@book{hermann2011sonification,
  title={The sonification handbook},
  author={Hermann, Thomas and Hunt, Andy and Neuhoff, John G},
  year={2011},
  publisher={Logos Verlag Berlin}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%       Geometry/Curve Processing           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

@article{mokhtarian1992theory,
  title={A theory of multiscale, curvature-based shape representation for planar curves},
  author={Mokhtarian, Farzin and Mackworth, Alan K},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={14},
  number={8},
  pages={789--805},
  year={1992}
}


@incollection{teukolsky2007section,
  title={Section 10.2.: Golden section search in one dimension},
  author={Teukolsky, WH and Vetterling, S and Flannery, W},
  booktitle={Numerical Recipes: The Art of Scientific Computing},
  pages={492--496},
  year={2007},
  publisher={Cambridge Univ. Press}
}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%          Audio Steganography              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


@article{ali_high_2018,
	title = {High capacity, transparent and secure audio steganography model based on fractal coding and chaotic map in temporal domain},
	volume = {77},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-018-6213-0},
	doi = {10.1007/s11042-018-6213-0},
	abstract = {Information hiding researchers have been exploring techniques to improve the security of transmitting sensitive data through an unsecured channel. This paper proposes an audio steganography model for secure audio transmission during communication based on fractal coding and a chaotic least significant bit or also known as {HASFC}. This model contributes to enhancing the hiding capacity and preserving the statistical transparency and security. The {HASFC} model manages to embed secret audio into a cover audio with the same size. In order to achieve this result, fractal coding is adopted which produces high compression ratio with the acceptable reconstructed signal. The chaotic map is used to randomly select the cover samples for embedding and its initial parameters are utilized as a secret key to enhancing the security of the proposed model. Unlike the existing audio steganography schemes, The {HASFC} model outperforms related studies by improving the hiding capacity up to 30\% and maintaining the transparency of stego audio with average values of {SNR} at 70.4, {PRD} at 0.0002 and {SDG} at 4.7. Moreover, the model also shows resistance against brute-force attack and statistical analysis.},
	pages = {31487--31516},
	number = {23},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Ali, Ahmed Hussain and George, Loay Edwar and Zaidan, A. A. and Mokhtar, Mohd Rosmadi},
	urldate = {2022-07-25},
	date = {2018-12},
	langid = {english},
	file = {Ali et al. - 2018 - High capacity, transparent and secure audio stegan.pdf:/home/ctralie/Zotero/storage/3AKQKJS5/Ali et al. - 2018 - High capacity, transparent and secure audio stegan.pdf:application/pdf},
}

@inproceedings{eichelberger_receiving_2019,
	location = {Santa Cruz {CA} {USA}},
	title = {Receiving Data Hidden in Music},
	isbn = {978-1-4503-6273-3},
	url = {https://dl.acm.org/doi/10.1145/3301293.3302360},
	doi = {10.1145/3301293.3302360},
	abstract = {This paper presents a method for transmitting data within music played from loudspeakers. The data is hidden in the music by leveraging the psychoacoustic masking effect, so that humans are not disturbed by the data transmission. The system achieves data rates of over 900 bits per second. The client side of the system could be implemented as a smartphone app, which receives data wherever users are without requiring any setup, making the system user-friendly.},
	eventtitle = {{HotMobile} '19: The 20th International Workshop on Mobile Computing Systems and Applications},
	pages = {33--38},
	booktitle = {Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications},
	publisher = {{ACM}},
	author = {Eichelberger, Manuel and Tanner, Simon and Voirol, Gabriel and Wattenhofer, Roger},
	urldate = {2022-07-25},
	date = {2019-02-22},
	langid = {english},
	file = {Eichelberger et al. - 2019 - Receiving Data Hidden in Music.pdf:/home/ctralie/Zotero/storage/63EWAHUV/Eichelberger et al. - 2019 - Receiving Data Hidden in Music.pdf:application/pdf},
}

@article{djebbar_comparative_2012,
	title = {Comparative study of digital audio steganography techniques},
	volume = {2012},
	issn = {1687-4722},
	url = {https://asmp-eurasipjournals.springeropen.com/articles/10.1186/1687-4722-2012-25},
	doi = {10.1186/1687-4722-2012-25},
	abstract = {The rapid spread in digital data usage in many real life applications have urged new and eﬀective ways to ensure their security. Eﬃcient secrecy can be achieved, at least in part, by implementing steganograhy techniques. Novel and versatile audio steganographic methods have been proposed. The goal of steganographic systems is to obtain secure and robust way to conceal high rate of secret data. We focus in this paper on digital audio steganography, which has emerged as a prominent source of data hiding across novel telecommunication technologies such as covered voice-over-{IP}, audio conferencing, etc. The multitude of steganographic criteria has led to a great diversity in these system design techniques. In this paper, we review current digital audio steganographic techniques and we evaluate their performance based on robustness, security and hiding capacity indicators. Another contribution of this paper is the provision of a robustness-based classiﬁcation of steganographic models depending on their occurrence in the embedding process. A survey of major trends of audio steganography applications is also discussed in this paper.},
	pages = {25},
	number = {1},
	journaltitle = {{EURASIP} Journal on Audio, Speech, and Music Processing},
	shortjournal = {J {AUDIO} {SPEECH} {MUSIC} {PROC}.},
	author = {Djebbar, Fatiha and Ayad, Beghdad and Meraim, Karim Abed and Hamam, Habib},
	urldate = {2022-07-25},
	date = {2012-12},
	langid = {english},
	file = {Djebbar et al. - 2012 - Comparative study of digital audio steganography t.pdf:/home/ctralie/Zotero/storage/HD7GX62U/Djebbar et al. - 2012 - Comparative study of digital audio steganography t.pdf:application/pdf},
}

@article{dutta_overview_2020,
	title = {An Overview of Digital Audio Steganography},
	volume = {37},
	issn = {0256-4602, 0974-5971},
	url = {https://www.tandfonline.com/doi/full/10.1080/02564602.2019.1699454},
	doi = {10.1080/02564602.2019.1699454},
	abstract = {Steganography deals with concealing of some messages via some media, which in digital domain is made over speech, image or video. In current generation, privacy related matters are of concern to every individual, that makes steganography to have an imperative role in real world applications. Audio signals are used as covers more frequently as compared with the other cover signals; the reason being their larger size so that more information can be concealed in the cover. Moreover, digital audio signals possess higher redundancy and high data transmission rate that make these suitable for used as covers. This work focuses on audio steganography based approaches that have effectuated attention from different researchers with its applicability to audio and speech signal processing for communicating information. In this work, different techniques, along with their algorithms and principles, useful in this regard are reviewed and a compendium to digital audio steganography is presented. Additionally, a comparative study among the existing approaches has been provided along with a critical review that can help the community to investigate particular approach according to the requirement.},
	pages = {632--650},
	number = {6},
	journaltitle = {{IETE} Technical Review},
	shortjournal = {{IETE} Technical Review},
	author = {Dutta, Hrishikesh and Das, Rohan Kumar and Nandi, Sukumar and Prasanna, S. R. Mahadeva},
	urldate = {2022-07-25},
	date = {2020-11-01},
	langid = {english},
	file = {Dutta et al. - 2020 - An Overview of Digital Audio Steganography.pdf:/home/ctralie/Zotero/storage/EUSHZQQA/Dutta et al. - 2020 - An Overview of Digital Audio Steganography.pdf:application/pdf},
}

@inproceedings{gopalan_unified_2009,
	location = {Churchill, Victoria, Australia},
	title = {A unified audio and image steganography by spectrum modification},
	isbn = {978-1-4244-3506-7},
	url = {http://ieeexplore.ieee.org/document/4939516/},
	doi = {10.1109/ICIT.2009.4939516},
	abstract = {A method of embedding information in the spectral domain of a cover audio and a cover image that can be extended to video frames is proposed. The technique exploits the imperceptibility of human auditory and visual systems at low levels of spectral changes. By selectively altering the spectrum at a pair of one-dimensional frequencies by a small percentage of the average power of a segment of audio or image, the psychoacoustical or psychovisual masking property enables unnoticeable embedding with a large payload. Initial studies on the effect of Gaussian noise added to the stego demonstrate the robustness of the technique to noise in both the stego audio and image. The imperceptibility of the technique combined with high payload, robustness of embedded data and accurate data retrieval renders the proposed steganography suitable for covert communication and secure data transmission applications.},
	eventtitle = {2009 {IEEE} International Conference on Industrial Technology - ({ICIT})},
	pages = {1--5},
	booktitle = {2009 {IEEE} International Conference on Industrial Technology},
	publisher = {{IEEE}},
	author = {Gopalan, Kaliappan},
	urldate = {2022-07-25},
	date = {2009-02},
	langid = {english},
	file = {Gopalan - 2009 - A unified audio and image steganography by spectru.pdf:/home/ctralie/Zotero/storage/7WM9FJLX/Gopalan - 2009 - A unified audio and image steganography by spectru.pdf:application/pdf},
}

@inproceedings{gopalan2004audio,
  title={Audio steganography for covert data transmission by imperceptible tone insertion},
  author={Gopalan, Kaliappan and Wenndt, Stanley},
  booktitle={Proc. The IASTED International Conference on Communication Systems And Applications (CSA 2004), Banff, Canada},
  year={2004}
}

@article{malik_robust_2007,
	title = {Robust Data Hiding in Audio Using Allpass Filters},
	volume = {15},
	issn = {1558-7916},
	url = {http://ieeexplore.ieee.org/document/4156208/},
	doi = {10.1109/TASL.2007.894509},
	abstract = {A novel technique is proposed for data hiding in digital audio that exploits the low sensitivity of the human auditory system to phase distortion. Inaudible but controlled phase changes are introduced in the host audio using a set of allpass ﬁlters ({APFs}) with distinct parameters of allpass ﬁlters, i.e., pole-zero locations. The {APF} parameters are chosen to encode the embedding information. During the detection phase, the power spectrum of the audio data is estimated in the -plane away from the unit circle. The power spectrum is used to estimate {APF} pole locations, for information decoding. Experimental results show that the proposed data hiding scheme can effectively withstand standard data manipulation attacks. Moreover, the proposed scheme is shown to embed 5–8 times more data than the existing audio data hiding schemes while providing comparable perceptual performance and robustness.},
	pages = {1296--1304},
	number = {4},
	journaltitle = {{IEEE} Transactions on Audio, Speech and Language Processing},
	shortjournal = {{IEEE} Trans. Audio Speech Lang. Process.},
	author = {Malik, Hafiz M. A. and Ansari, Rashid and Khokhar, Ashfaq A.},
	urldate = {2022-07-25},
	date = {2007-05},
	langid = {english},
	file = {Malik et al. - 2007 - Robust Data Hiding in Audio Using Allpass Filters.pdf:/home/ctralie/Zotero/storage/F8E32WEN/Malik et al. - 2007 - Robust Data Hiding in Audio Using Allpass Filters.pdf:application/pdf},
}

@inproceedings{eichelberger_imperceptible_2019,
	location = {Brighton, United Kingdom},
	title = {Imperceptible Audio Communication},
	isbn = {978-1-4799-8131-1},
	url = {https://ieeexplore.ieee.org/document/8682262/},
	doi = {10.1109/ICASSP.2019.8682262},
	abstract = {A differential acoustic {OFDM} technique is presented to embed data imperceptibly in existing music. The method allows playing back music containing the data with a speaker without users noticing the embedded data channel. Using a microphone, the data can be recovered from the recording. Experiments with smartphone microphones show that transmission distances of 24 meters are possible, while achieving bit error ratios of less than 10 percent, depending on the environment. Furthermore, we present a user study which shows that many people do not recognize the added data channel in music, even when being informed about the experiment and therefore actively listening for the data transmission. Depending on the source music, data rates of 300 to 400 bits per second are achieved.},
	eventtitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {680--684},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	publisher = {{IEEE}},
	author = {Eichelberger, Manuel and Tanner, Simon and Voirol, Gabriel and Wattenhofer, Roger},
	urldate = {2022-07-25},
	date = {2019-05},
	langid = {english},
	file = {Eichelberger et al. - 2019 - Imperceptible Audio Communication.pdf:/home/ctralie/Zotero/storage/I38VFLY8/Eichelberger et al. - 2019 - Imperceptible Audio Communication.pdf:application/pdf},
}

@article{carvalho_mp4stego_2009,
	title = {{MP}4Stego: steganography in {MPEG}-4 videos},
	volume = {3},
	issn = {1462-4613, 1741-8003},
	url = {http://www.inderscience.com/link.php?id=28712},
	doi = {10.1504/IJAMC.2009.028712},
	shorttitle = {{MP}4Stego},
	abstract = {Steganography in digital videos makes possible to hide a great quantity of information when compared to techniques used in images. However, direct image techniques cannot be simply applied to compressed videos because temporal compression add noise to the hidden information potentially making it useless. This work presents a steganography technique called {MP}4Stego, which explores the {MPGEG}-4 encoding standard in order to recover hidden information without lost. Some beneﬁts of {MP}4Stego are: hiding of large amounts of data; reproducing the video having hidden data in non specialised players; its immunity, up to now, to stegoanalysis techniques.},
	pages = {440},
	number = {4},
	journaltitle = {International Journal of Advanced Media and Communication},
	shortjournal = {{IJAMC}},
	author = {Carvalho, Diego F. and Goularte, Rudinei},
	urldate = {2022-07-25},
	date = {2009},
	langid = {english},
	file = {Carvalho and Goularte - 2009 - MP4Stego steganography in MPEG-4 videos.pdf:/home/ctralie/Zotero/storage/LR3QSUNA/Carvalho and Goularte - 2009 - MP4Stego steganography in MPEG-4 videos.pdf:application/pdf},
}

@inproceedings{qiao_steganalysis_2009,
	location = {Atlanta, Ga, {USA}},
	title = {Steganalysis of {MP}3Stego},
	isbn = {978-1-4244-3548-7},
	url = {http://ieeexplore.ieee.org/document/5178971/},
	doi = {10.1109/IJCNN.2009.5178971},
	abstract = {In this article, we propose a scheme for detecting hidden messages in compressed audio files produced by {MP}3Stego, as our literature search has found no previous work on successful steganalysis of {MP}3Stego. We extract moment statistical features on the second derivatives, as well as Markov transition features and neighboring joint density of the {MDCT} coefficients based on each specific frequency band on {MPEG}-1 Audio Layer 3. A support vector machine is applied to different feature sets for classification. Experimental results show that our approach is successful to discriminate {MP}3 covers and the steganograms generated by using {MP}3Stego.},
	eventtitle = {2009 International Joint Conference on Neural Networks ({IJCNN} 2009 - Atlanta)},
	pages = {2566--2571},
	booktitle = {2009 International Joint Conference on Neural Networks},
	publisher = {{IEEE}},
	author = {Qiao, Mengyu and Sung, Andrew H. and Liu, Qingzhong},
	urldate = {2022-07-25},
	date = {2009-06},
	langid = {english},
	file = {Qiao et al. - 2009 - Steganalysis of MP3Stego.pdf:/home/ctralie/Zotero/storage/IQVELTPQ/Qiao et al. - 2009 - Steganalysis of MP3Stego.pdf:application/pdf},
}

@inproceedings{xiaoxiao_dong_data_2004,
	location = {Montreal, Que., Canada},
	title = {Data hiding via phase manipulation of audio signals},
	volume = {5},
	isbn = {978-0-7803-8484-2},
	url = {http://ieeexplore.ieee.org/document/1327126/},
	doi = {10.1109/ICASSP.2004.1327126},
	abstract = {Data hiding in media, including images, video, and audio, as well as in data files is currently of great interest both commercially, mainly for the protection of copyrighted digital media, and to the government and law enforcement in the context of information systems security and covert communications. In this paper we present a technique for inserting and recovering “hidden” data in audio files. In this technique the phase of chosen components of the host audio signal is manipulated in a way that may be detected by a receiver with the proper “key”. Without the key, the hidden data is undetectable, both aurally and via blind digital signal processing attacks. The method described is both aurally transparent and robust and can be applied to both analog and digital audio signals, the latter including uncompressed as well as compressed audio file formats such as {MP}3.},
	eventtitle = {2004 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	pages = {V--377--80},
	booktitle = {2004 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	publisher = {{IEEE}},
	author = {{Xiaoxiao Dong} and Bocko, M.F. and Ignjatovic, Z.},
	urldate = {2022-07-25},
	date = {2004},
	langid = {english},
	file = {Xiaoxiao Dong et al. - 2004 - Data hiding via phase manipulation of audio signal.pdf:/home/ctralie/Zotero/storage/BLWJ48E6/Xiaoxiao Dong et al. - 2004 - Data hiding via phase manipulation of audio signal.pdf:application/pdf},
}

@article{yi_ahcm_2019,
	title = {{AHCM}: Adaptive Huffman Code Mapping for Audio Steganography Based on Psychoacoustic Model},
	volume = {14},
	issn = {1556-6013, 1556-6021},
	url = {https://ieeexplore.ieee.org/document/8626153/},
	doi = {10.1109/TIFS.2019.2895200},
	shorttitle = {{AHCM}},
	abstract = {Most current audio steganographic methods are content non-adaptive which have poor security and low embedding capacity. This paper proposes a generalized adaptive Huffman code mapping ({AHCM}) framework for obtaining higher secure payload. To avoid the frame-offset effect of audio codec, we ﬁrst establish a distortion-limited suppressible code space, which realizes data embedding by using equal-length entropy codes. Furthermore, a stego key is used to dynamically build Huffman code mapping of each frame for improving acoustic imperceptibility and statistical undetectability. We then consider integrating psychoacoustic model ({PAM}) of intra-frame with frame-level perceptual distortion of inter-frame to obtain minimized total distortion. Finally, we present an implementation of the proposed {AHCM} framework on {MP}3 audios. A distortion function based on the {PAM} and an optimal steganographic frame path are, respectively, devised for adaptively embedding via employing syndrome-trellis codes. Experimental results demonstrate that our approach is, indeed, able to achieve higher secure steganographic capacity and better acoustic concealment. The detection accuracy of 320-kbps-mp3 datasets is lower than 65\% when the embedding payload reaches 11 kbps, which is decreased by 11.8\%–13.4\% than the state-of-the-art steganographic methods.},
	pages = {2217--2231},
	number = {8},
	journaltitle = {{IEEE} Transactions on Information Forensics and Security},
	shortjournal = {{IEEE} Trans.Inform.Forensic Secur.},
	author = {Yi, Xiaowei and Yang, Kun and Zhao, Xianfeng and Wang, Yuntao and Yu, Haibo},
	urldate = {2022-07-25},
	date = {2019-08},
	langid = {english},
	file = {Yi et al. - 2019 - AHCM Adaptive Huffman Code Mapping for Audio Steg.pdf:/home/ctralie/Zotero/storage/L8DCHBYS/Yi et al. - 2019 - AHCM Adaptive Huffman Code Mapping for Audio Steg.pdf:application/pdf},
}

@article{ali_review_2016,
	title = {A Review on Audio Steganography Techniques},
	abstract = {The aim of this study is to present different types of steganography in brief and to give a special attention to audio steganography technique because a huge number of audio files are exchanged through the networks. Nowadays the widening of attacker's abilities to access the private and public information transmitted over public communication system makes way for highlighting a tool that guarantees the secure transmission of hidden information. Information hiding was a common security term that mainly includes three techniques: cryptography, steganography and watermark. Cryptography was an ancient form that is used for confidential data. Steganography is a popular tool that uses digital medium to hide confidential data in innocent carrier such as image, audio, text and video. Steganography is in fact a complement for the earlier data hiding technique cryptography. However watermark is used for copyright protection. Audio steganography is technique that hides any type of secret data in cover audio file. This study also discusses the main requirements of steganography methods and how those methods achieve them. Furthermore it shows steganography domain and, carriers and information hiding techniques used in audio.},
	pages = {9},
	author = {Ali, Ahmed Hussain and George, {LoayEdwar}},
	date = {2016},
	langid = {english},
	file = {Ali and George - 2016 - A Review on Audio Steganography Techniques.pdf:/home/ctralie/Zotero/storage/H2XFDVXK/Ali and George - 2016 - A Review on Audio Steganography Techniques.pdf:application/pdf},
}

@article{madhavapeddy_audio_2005,
	title = {Audio Networking: The Forgotten Wireless Technology},
	volume = {4},
	issn = {1536-1268},
	url = {http://ieeexplore.ieee.org/document/1495392/},
	doi = {10.1109/MPRV.2005.50},
	shorttitle = {Audio Networking},
	pages = {55--60},
	number = {3},
	journaltitle = {{IEEE} Pervasive Computing},
	shortjournal = {{IEEE} Pervasive Comput.},
	author = {Madhavapeddy, A. and Scott, D. and Tse, A. and Sharp, R.},
	urldate = {2022-07-25},
	date = {2005-07},
	langid = {english},
	file = {Madhavapeddy et al. - 2005 - Audio Networking The Forgotten Wireless Technolog.pdf:/home/ctralie/Zotero/storage/GEA37BK9/Madhavapeddy et al. - 2005 - Audio Networking The Forgotten Wireless Technolog.pdf:application/pdf;Santosa Bao.pdf:/home/ctralie/Zotero/storage/NCPZ7ZT9/Santosa Bao.pdf:application/pdf},
}

@article{hwan_sik_yun_acoustic_2010,
	title = {Acoustic Data Transmission Based on Modulated Complex Lapped Transform},
	volume = {17},
	issn = {1070-9908, 1558-2361},
	url = {http://ieeexplore.ieee.org/document/5256179/},
	doi = {10.1109/LSP.2009.2032751},
	abstract = {Acoustic data transmission is a technique to embed the data in a sound wave imperceptibly and to detect it at the receiver. This letter proposes a novel acoustic data transmission system designed based on the modulated complex lapped transform ({MCLT}). In the proposed system, data is embedded in an audio ﬁle by modifying the phases of the original {MCLT} coefﬁcients. The data can be transmitted by playing the embedded audio and extracting it from the received audio. By embedding the data in the {MCLT} domain, the perceived quality of the resulting audio could be kept almost similar as the original audio. The system can transmit data at several hundreds of bits per second (bps), which is sufﬁcient to deliver some useful short messages.},
	pages = {67--70},
	number = {1},
	journaltitle = {{IEEE} Signal Processing Letters},
	shortjournal = {{IEEE} Signal Process. Lett.},
	author = {{Hwan Sik Yun} and {Kiho Cho} and {Nam Soo Kim}},
	urldate = {2022-07-25},
	date = {2010-01},
	langid = {english},
	file = {Hwan Sik Yun et al. - 2010 - Acoustic Data Transmission Based on Modulated Comp.pdf:/home/ctralie/Zotero/storage/HLU8G5PV/Hwan Sik Yun et al. - 2010 - Acoustic Data Transmission Based on Modulated Comp.pdf:application/pdf},
}




@article{hmood2012new,
  title={A new steganographic method for embedded image in audio file},
  author={Hmood, Dalal N and Khudhiar, Khamael A and Altaei, Mohammad S},
  journal={International Journal of Computer Science and Security (IJCSS)},
  volume={6},
  number={2},
  pages={135--141},
  year={2012}
}

@inproceedings{cvejic_wavelet_2002,
	location = {Pine Mountain, {GA}, {USA}},
	title = {A wavelet domain {LSB} insertion algorithm for high capacity audio steganography},
	isbn = {978-0-7803-8116-2},
	url = {http://ieeexplore.ieee.org/document/1231075/},
	doi = {10.1109/DSPWS.2002.1231075},
	abstract = {In this work, we increased the capacity of the classic {LSB} insertion method by performing the embedding process in the wavelet domain. The algorithm uses perfect reconstruction filterbanks and embeds additional information inside wavelet domain of audio signal by modifying {LSB} values of wavelet coefficients. Objective and subjective tests show large advantage of the proposed method over time insertion method. For the same {SNR} values, proposed algorithm outperforms classical {LSB} algorithm by 150-200 kbps of hidden data. Subjective experiments showed that wavelet domain information hiding scheme is acoustically more transparent as well.},
	eventtitle = {10th {IEEE} Signal Processing Society Digital Signal Processing},
	pages = {53--55},
	booktitle = {Proceedings of 2002 {IEEE} 10th Digital Signal Processing Workshop, 2002 and the 2nd Signal Processing Education Workshop.},
	publisher = {{IEEE}},
	author = {Cvejic, N. and Seppanen, T.},
	urldate = {2022-08-08},
	date = {2002},
	langid = {english},
	file = {Cvejic and Seppanen - 2002 - A wavelet domain LSB insertion algorithm for high .pdf:/home/ctralie/Zotero/storage/XSUED3RL/Cvejic and Seppanen - 2002 - A wavelet domain LSB insertion algorithm for high .pdf:application/pdf},
}


@inproceedings{santosa_audio--image_2005,
	location = {Zadar, Croatia},
	title = {Audio-to-image wavelet transform based audio steganography},
	url = {http://ieeexplore.ieee.org/document/1505680/},
	doi = {10.1109/ELMAR.2005.193679},
	abstract = {In this paper, we propose an audio steganogruphic scheme based on wavelet audio-to-image transform. The scheme converts the audio steganographic issue into well-explored image steganographic one. In the scheme, the host audio sigplal is transformed into image, the covert datu are embedded in the image by an image steganographic scheme und finuily, the image is transfomed back info audio signal. Theperformance of the proposed scheme under {MP}3 compression is shown in the experimental results.},
	eventtitle = {47th International Symposium {ELMAR}, 2005.},
	pages = {209--212},
	booktitle = {47th International Symposium {ELMAR}, 2005.},
	publisher = {{IEEE}},
	author = {Santosa, R.A. and Bao, P.},
	urldate = {2022-10-17},
	date = {2005},
	langid = {english},
	file = {Santosa and Bao - 2005 - Audio-to-image wavelet transform based audio stega.pdf:/home/ctralie/Zotero/storage/B8UG2S6D/Santosa and Bao - 2005 - Audio-to-image wavelet transform based audio stega.pdf:application/pdf},
}

@article{bassia2001robust,
  title={Robust audio watermarking in the time domain},
  author={Bassia, Paraskevi and Pitas, Ioannis and Nikolaidis, Nikos},
  journal={IEEE Transactions on multimedia},
  volume={3},
  number={2},
  pages={232--241},
  year={2001},
  publisher={IEEE}
}



%% Deep learning based

@article{kreuk2020hide,
  title={Hide and Speak: Towards Deep Neural Networks for Speech Steganography},
  author={Kreuk, Felix and Adi, Yossi and Raj, Bhiksha and Singh, Rita and Keshet, Joseph},
  year={2020}
}


@article{wu2020audio,
  title={Audio steganography based on iterative adversarial attacks against convolutional neural networks},
  author={Wu, Junqi and Chen, Bolin and Luo, Weiqi and Fang, Yanmei},
  journal={IEEE transactions on information forensics and security},
  volume={15},
  pages={2282--2294},
  year={2020},
  publisher={IEEE}
}

@misc{takahashi_source_2022,
	title = {Source Mixing and Separation Robust Audio Steganography},
	url = {http://arxiv.org/abs/2110.05054},
	abstract = {Audio steganography aims at concealing secret information in carrier audio with imperceptible modiﬁcation on the carrier. Although previous works addressed the robustness of concealed message recovery against distortions introduced during transmission, they do not address the robustness against aggressive editing such as mixing of other audio sources and source separation. In this work, we propose for the ﬁrst time a steganography method that can embed information into individual sound sources in a mixture such as instrumental tracks in music. To this end, we propose a time-domain model and curriculum learning essential to learn to decode the concealed message from the separated sources. Experimental results show that the proposed method successfully conceals the information in an imperceptible perturbation and that the information can be correctly recovered even after mixing of other sources and separation by a source separation algorithm. Furthermore, we show that the proposed method can be applied to multiple sources simultaneously without interfering with the decoder for other sources even after the sources are mixed and separated.},
	number = {{arXiv}:2110.05054},
	publisher = {{arXiv}},
	author = {Takahashi, Naoya and Singh, Mayank Kumar and Mitsufuji, Yuki},
	urldate = {2022-08-01},
	date = {2022-02-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2110.05054 [cs, eess]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Takahashi et al. - 2022 - Source Mixing and Separation Robust Audio Steganog.pdf:/home/ctralie/Zotero/storage/2AHDNU5N/Takahashi et al. - 2022 - Source Mixing and Separation Robust Audio Steganog.pdf:application/pdf},
}

@misc{geleta_pixinwav_2021,
	title = {{PixInWav}: Residual Steganography for Hiding Pixels in Audio},
	url = {http://arxiv.org/abs/2106.09814},
	shorttitle = {{PixInWav}},
	abstract = {Steganography comprises the mechanics of hiding data in a host media that may be publicly available. While previous works focused on unimodal setups (e.g., hiding images in images, or hiding audio in audio), {PixInWav} targets the multimodal case of hiding images in audio. To this end, we propose a novel residual architecture operating on top of short-time discrete cosine transform ({STDCT}) audio spectrograms. Among our results, we ﬁnd that the residual audio steganography setup we propose allows independent encoding of the hidden image from the host audio without compromising quality. Accordingly, while previous works require both host and hidden signals to hide a signal, {PixInWav} can encode images ofﬂine — which can be later hidden, in a residual fashion, into any audio signal. Finally, we test our scheme in a lab setting to transmit images over airwaves from a loudspeaker to a microphone verifying our theoretical insights and obtaining promising results.},
	number = {{arXiv}:2106.09814},
	publisher = {{arXiv}},
	author = {Geleta, Margarita and Punti, Cristina and {McGuinness}, Kevin and Pons, Jordi and Canton, Cristian and Giro-i-Nieto, Xavier},
	urldate = {2022-08-01},
	date = {2021-06-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.09814 [cs, eess]},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Multimedia},
	file = {Geleta et al. - 2021 - PixInWav Residual Steganography for Hiding Pixels.pdf:/home/ctralie/Zotero/storage/BWHEC7D4/Geleta et al. - 2021 - PixInWav Residual Steganography for Hiding Pixels.pdf:application/pdf},
}

@misc{cui_multi-stage_2021,
	title = {Multi-Stage Residual Hiding for Image-into-Audio Steganography},
	url = {http://arxiv.org/abs/2101.01872},
	abstract = {The widespread application of audio communication technologies has speeded up audio data ﬂowing across the Internet, which made it a popular carrier for covert communication. In this paper, we present a cross-modal steganography method for hiding image content into audio carriers while preserving the perceptual ﬁdelity of the cover audio. In our framework, two multi-stage networks are designed: the ﬁrst network encodes the decreasing multilevel residual errors inside different audio subsequences with the corresponding stage sub-networks, while the second network decodes the residual errors from the modiﬁed carrier with the corresponding stage sub-networks to produce the ﬁnal revealed results. The multi-stage design of proposed framework not only make the controlling of payload capacity more ﬂexible, but also make hiding easier because of the gradual sparse characteristic of residual errors. Qualitative experiments suggest that modiﬁcations to the carrier are unnoticeable by human listeners and that the decoded images are highly intelligible.},
	number = {{arXiv}:2101.01872},
	publisher = {{arXiv}},
	author = {Cui, Wenxue and Liu, Shaohui and Jiang, Feng and Liu, Yongliang and Zhao, Debin},
	urldate = {2022-10-17},
	date = {2021-01-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2101.01872 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
	file = {Cui et al. - 2021 - Multi-Stage Residual Hiding for Image-into-Audio S.pdf:/home/ctralie/Zotero/storage/4GRMZVG7/Cui et al. - 2021 - Multi-Stage Residual Hiding for Image-into-Audio S.pdf:application/pdf},
}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%             Other Citations               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

@misc{Ball2022,
  author = {Ball, James H.},
  title = {Osci-Render: A Programing for Making Music by Drawing Objects, Text, And Images on An Oscilloscope Using Audio Output},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jameshball/osci-render}},
  commit = {7df9b0fa62c6db477625c0a87e173e5f702d6f1b}
}


@article{mathews2004music,
  title={Music in His Own Image: The Aphex Twin Face.},
  author={Mathews, Peter David},
  journal={Nebula},
  volume={1},
  number={1},
  pages={65--73},
  year={2004}
}


@article{schwarz2007corpus,
  title={Corpus-based concatenative synthesis},
  author={Schwarz, Diemo},
  journal={IEEE signal processing magazine},
  volume={24},
  number={2},
  pages={92--104},
  year={2007},
  publisher={IEEE}
}

@incollection{LONG201481,
title = {3 - Human Perception and Reaction to Sound},
editor = {Marshall Long},
booktitle = {Architectural Acoustics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Boston},
pages = {81-127},
year = {2014},
isbn = {978-0-12-398258-2},
doi = {https://doi.org/10.1016/B978-0-12-398258-2.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780123982582000039},
author = {Marshall Long},
keywords = {pitch, critical bands, physiology of the ear, loudness, frequency weighting networks, noise curves, masking, articulation, time averaging, binaural sound},
abstract = {Chapter 3 discusses the mechanisms of human hearing including a description of the ear (its physiology and anatomy), the perception of pitch, loudness, speech intelligibility, annoyance, health and safety considerations, and other acoustical effects. There are detailed discussions of various phenomena including perception of level, direction, binaural sound, background noise standards (including the U.S. Environmental Protection Agency (EPA) and the U.S. Occupational Safety and Health Administration (OSHA) standards) and echoes. Metrics are discussed including time averaging, 24-hour levels, speech intelligibility, and thresholds of perception.}
}

@online{pianorollafrica,
title = {Musical World Map - Africa},
date = {2017},
organization = {Youtube},
author = {John Keats and HybridShark},
url = {https://www.youtube.com/watch?v=q9_WG7eXelo},
}

@article{griffin1984signal,
  title={Signal estimation from modified short-time Fourier transform},
  author={Griffin, Daniel and Lim, Jae},
  journal={IEEE Transactions on acoustics, speech, and signal processing},
  volume={32},
  number={2},
  pages={236--243},
  year={1984},
  publisher={IEEE}
}


@article{lewisfast,
  title={Fast template matching, vision interface 95},
  author={Lewis, J},
  journal={Canadian Image Processing and Pattern Recognition Society},
  pages={15--19}
}


@misc{li_andreeto_ranzato_perona_2022, title={Caltech 101}, DOI={10.22002/D1.20086}, abstractNote={Pictures of objects belonging to 101 categories. About 40 to 800 images per category. Most categories have about 50 images. Collected in September 2003 by Fei-Fei Li, Marco Andreetto, and Marc'Aurelio Ranzato. The size of each image is roughly 300 x 200 pixels. We have carefully clicked outlines of each object in these pictures, these are included under the 'Annotations.tar'. There is also a MATLAB script to view the annotations, 'show_annotations.m'.}, publisher={CaltechDATA}, author={Li and Andreeto and Ranzato and Perona}, year={2022}, month={Apr} }